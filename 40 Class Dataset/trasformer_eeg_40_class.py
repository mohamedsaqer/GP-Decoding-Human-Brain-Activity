# -*- coding: utf-8 -*-
"""trasformer Block EEG 40 class.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qlvDmWJwEOuBw2_XQie2o3w_LhFFRJGe
"""

from google.colab import drive
drive.mount('/content/drive')
from tensorflow.python.keras.backend import clear_session
import tensorflow as tf,keras
from tensorflow.keras import layers
import numpy as np
import matplotlib.pylab as plt
import torch.utils.data as data
#import h5py
#import csv
from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint
import torch
import keras
from tensorflow.keras.models import Sequential
from keras.layers import Input, Dense, LSTM,Dropout
from keras.utils import to_categorical
from keras.models import Model
from torchvision import transforms

"""# class EEGloader
loadData

"""

class eegloader(data.Dataset):
	def __init__(self, data_path, split_path, dtype='train', data_dir='./', split_no=0, dlen=160, stpt=320, nch=128):

		data = torch.load(data_dir + data_path)
		split = torch.load(data_dir + split_path)
		self.mean = data['means']
		self.stdev = data['stddevs']
		self.labels = split['splits'][split_no][dtype]

		self.data = []
		for l in self.labels:
			self.data.append(data['dataset'][l])

		assert len(self.data)==len(self.labels)
		self.dlen = dlen
		self.stpt = stpt
		self.nch = nch

	def __len__(self):
		return len(self.data)
	
	def __getitem__(self, idx):
		nch  = self.nch
		dlen = self.dlen 
		stpt = self.stpt
	
		x = np.zeros((nch,dlen))
		y = self.data[idx]['label']
		s = self.data[idx]['subject'] 
		
		x = torch.from_numpy(x)
		x[:,:min(int(self.data[idx]['eeg'].shape[1]),dlen)] = self.data[idx]['eeg'][:,stpt:stpt+dlen]
		x = x.type(torch.FloatTensor).sub(self.mean.expand(nch,dlen))/ self.stdev.expand(nch,dlen)

		return x, y, s

def load_data():
  
  data_dir = path
  data_path = 'eeg_signals_128_sequential_band_all_with_mean_std.pth'
  split_path = 'block_splits_by_image.pth'
  split_no = 0

  x = eegloader(data_path, split_path, dtype='train', data_dir=data_dir, split_no=split_no,dlen=l_sh, stpt=r_sh)
  y = eegloader(data_path, split_path, dtype='val', data_dir=data_dir, split_no=split_no,dlen=l_sh, stpt=r_sh)
  z = eegloader(data_path, split_path, dtype='test', data_dir=data_dir, split_no=split_no,dlen=l_sh, stpt=r_sh)

  x_train=[]
  y_train=[]
  x_test=[]
  y_test=[]
  for i in range(len(x)):
    x_train.append(tf.make_ndarray(tf.make_tensor_proto(x[i][0])))
    y_train.append(x[i][1])

  for i in range(len(y)):
    x_train.append(tf.make_ndarray(tf.make_tensor_proto(y[i][0])))
    y_train.append(y[i][1])

  for i in range(len(z)):
    x_test.append(tf.make_ndarray(tf.make_tensor_proto(z[i][0])))
    y_test.append(z[i][1])


  x_train = np.array(x_train)
  y_train = np.array(y_train)
  x_test = np.array(x_test)
  y_test = np.array(y_test)
  del(x)
  del(y)
  del(z)
  return (x_train,y_train,x_test,y_test)

path = '/content/drive/My Drive/Dataset/eeg/'
l_sh = 200       ## diff
r_sh = 50   ## star of time point
diff = l_sh

x_train,y_train,x_test,y_test = load_data()
y_train1,y_test1 = y_train,y_test
train_size = x_train.shape[0]
test_size = x_test.shape[0]

"""#Transformer

"""

y_train1 = y_train
y_test1 = y_test
y_train = to_categorical(y_train, num_classes=40)
y_test = to_categorical(y_test, num_classes=40)
x_train = np.transpose(x_train,(0,2,1))
x_test = np.transpose(x_test,(0,2,1))
print(x_train.shape)

clear_session()

num_heads = 2  # Number of attention heads
ff_dim = 32  # Hidden layer size in feed forward network inside transformer

sequence_input = tf.keras.layers.Input(shape=(x_train.shape[1], x_train.shape[2]))
transformer_block = TransformerBlock(x_train.shape[2], num_heads, ff_dim)
x = transformer_block(sequence_input)
x = layers.GlobalAveragePooling1D()(x)
# x = layers.Dropout(0.1)(x)
x = layers.Dense(128, activation="relu")(x)
# x = layers.Dropout(0.1)(x)
outputs = layers.Dense(40, activation="softmax")(x)

classifier = tf.keras.Model(inputs=sequence_input, outputs=outputs)
adam = tf.keras.optimizers.Adam(lr=1e-4, decay=1e-7)
classifier.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])
classifier.summary()
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)
history = classifier.fit(x=x_train, y=y_train, validation_data=(x_test, y_test),
                          epochs=100, batch_size=32, callbacks=[es])
# plot training history
plot_train_history(history, note='note')
print(classifier.evaluate(x_test, y_test))

print(classifier.evaluate(x_test, y_test))

def plot_train_history(history, note=''):
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('model accuracy ' + note)
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()

class MultiHeadSelfAttention(layers.Layer):
    def __init__(self, embed_dim, num_heads=8):
        super(MultiHeadSelfAttention, self).__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        if embed_dim % num_heads != 0:
            raise ValueError(
                f"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}"
            )
        self.projection_dim = embed_dim // num_heads
        self.query_dense = layers.Dense(embed_dim)
        self.key_dense = layers.Dense(embed_dim)
        self.value_dense = layers.Dense(embed_dim)
        self.combine_heads = layers.Dense(embed_dim)

    def attention(self, query, key, value):
        score = tf.matmul(query, key, transpose_b=True)
        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)
        scaled_score = score / tf.math.sqrt(dim_key)
        weights = tf.nn.softmax(scaled_score, axis=-1)
        output = tf.matmul(weights, value)
        return output, weights

    def separate_heads(self, x, batch_size):
        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))
        return tf.transpose(x, perm=[0, 2, 1, 3])

    def call(self, inputs):
        # x.shape = [batch_size, seq_len, embedding_dim]
        batch_size = tf.shape(inputs)[0]
        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)
        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)
        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)
        query = self.separate_heads(
            query, batch_size
        )  # (batch_size, num_heads, seq_len, projection_dim)
        key = self.separate_heads(
            key, batch_size
        )  # (batch_size, num_heads, seq_len, projection_dim)
        value = self.separate_heads(
            value, batch_size
        )  # (batch_size, num_heads, seq_len, projection_dim)
        attention, weights = self.attention(query, key, value)
        attention = tf.transpose(
            attention, perm=[0, 2, 1, 3]
        )  # (batch_size, seq_len, num_heads, projection_dim)
        concat_attention = tf.reshape(
            attention, (batch_size, -1, self.embed_dim)
        )  # (batch_size, seq_len, embed_dim)
        output = self.combine_heads(
            concat_attention
        )  # (batch_size, seq_len, embed_dim)
        return output
  

class TransformerBlock(layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerBlock, self).__init__()
        self.att = MultiHeadSelfAttention(embed_dim, num_heads)
        self.ffn = keras.Sequential(
            [layers.Dense(ff_dim, activation="relu"), layers.Dense(embed_dim),]
        )
        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = layers.Dropout(rate)
        self.dropout2 = layers.Dropout(rate)

    def call(self, inputs, training):
        attn_output = self.att(inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

class TokenAndPositionEmbedding(layers.Layer):
    def __init__(self, maxlen, vocab_size, embed_dim):
        super(TokenAndPositionEmbedding, self).__init__()
        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)
        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)

    def call(self, x):
        maxlen = tf.shape(x)[-1]
        positions = tf.range(start=0, limit=maxlen, delta=1)
        positions = self.pos_emb(positions)
        x = self.token_emb(x)
        return x + positions
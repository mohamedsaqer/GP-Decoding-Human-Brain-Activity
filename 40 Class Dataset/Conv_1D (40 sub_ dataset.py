# -*- coding: utf-8 -*-
"""test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vrqp7YN_vfokCK6_pf-4dBjW5AQl9W3R
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
import torch
from tensorflow import keras
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
from tensorflow.keras import Input , Model
from tensorflow.keras.layers import Conv1D , MaxPooling1D , Flatten , Dense , UpSampling1D , Reshape ,AveragePooling1D, UpSampling1D

from torchvision import transforms
import torch.utils.data as data
import numpy as np
#from Dataloader import *
#from model import *
import torch.nn
import torch.optim as optim
from torch.autograd import Variable
import torch
class eegloader(data.Dataset):
	def __init__(self, data_path, split_path, dtype='train', data_dir='./', split_no=0, dlen=160, stpt=320, nch=128):

		data = torch.load(data_dir + data_path)
		split = torch.load(data_dir + split_path)

		self.mean = data['means']
		self.stdev = data['stddevs']
		self.labels = split['splits'][split_no][dtype]

		self.data = []
		for l in self.labels:
			self.data.append(data['dataset'][l])

		assert len(self.data)==len(self.labels)
		self.dlen = dlen
		self.stpt = stpt
		self.nch = nch

	def __len__(self):
		return len(self.data)
	
	def __getitem__(self, idx):
		nch  = self.nch
		dlen = self.dlen 
		stpt = self.stpt
	
		x = np.zeros((nch,dlen))
		y = self.data[idx]['label']
		s = self.data[idx]['subject'] 
		
		x = torch.from_numpy(x)
		x[:,:min(int(self.data[idx]['eeg'].shape[1]),dlen)] = self.data[idx]['eeg'][:,stpt:stpt+dlen]
		x = x.type(torch.FloatTensor).sub(self.mean.expand(nch,dlen))/ self.stdev.expand(nch,dlen)

		return x, y, s

data_dir = '/content/drive/MyDrive/'
batch_size = 128
data_path = 'eeg_signals_128_sequential_band_all_with_mean_std.pth'
split_path = 'block_splits_by_image.pth'
split_no = 3

#trainset = data.DataLoader(eegloader(data_path, split_path, dtype='train', data_dir=data_dir, split_no=split_no),batch_size=batch_size, shuffle=True)
#valset = data.DataLoader(eegloader(data_path, split_path, dtype='val', data_dir=data_dir, split_no=split_no),batch_size=batch_size)
#testset = data.DataLoader(eegloader(data_path, split_path, dtype='test', data_dir=data_dir, split_no=split_no),batch_size=batch_size)
#print('data loaded')

x = eegloader(data_path, split_path, dtype='train', data_dir=data_dir, split_no=split_no)
y = eegloader(data_path, split_path, dtype='val', data_dir=data_dir, split_no=split_no)
z = eegloader(data_path, split_path, dtype='test', data_dir=data_dir, split_no=split_no)

print(len(z))

training_x=[]
training_y=[]
testing_x=[]
testing_y=[]
for i in range(7972):
  training_x.append(tf.make_ndarray(tf.make_tensor_proto(x[i][0])))
  training_y.append(x[i][1])

for i in range(1997):
  testing_x.append(tf.make_ndarray(tf.make_tensor_proto(z[i][0])))
  testing_y.append(z[i][1])

training = np.array(training_x)
labeling = np.array(training_y)
test_x = np.array(testing_x)
test_y = np.array(testing_y)

input_sig = Input(shape=(128,160)) 
x = Conv1D(64,3, activation='relu', padding='valid',data_format='channels_first')(input_sig)
x_ = MaxPooling1D(2,data_format='channels_first')(x)
x1 = Conv1D(32,3, activation='relu', padding='valid',data_format='channels_first')(x_)
x1_ = MaxPooling1D(2,data_format='channels_first')(x1)
#x2 = Conv1D(64,3, activation='relu', padding='valid',data_format='channels_first')(x1_)
#x2_ = MaxPooling1D(2,data_format='channels_first')(x2)
flat = Flatten()(x1_)
dense = Dense(64,activation = 'relu')(flat)
encoded = Dense(40,activation = 'softmax')(dense)
autoencoder = Model(input_sig, encoded)
autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])

autoencoder.summary()

autoencoder.fit(training, labeling, epochs=200, verbose=1, validation_data=(test_x, test_y),batch_size=128)

labels = []
for i in range(7972):
  labels.append(tf.keras.utils.to_categorical(training_y[i], num_classes=40))
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Estimating EEG Vector from Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig8c11OpLjXR",
        "outputId": "fd9ec4af-9507-4ffc-9053-eb77d1d2b311"
      },
      "source": [
        "''' drive link for dataset and images \n",
        "https://drive.google.com/drive/folders/1FfaBEYCQvO7bY5YjtsgzuInkOStU6ABW?usp=sharing'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcpmbpXAFep3"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "import torch\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import  Dense, Input, Activation\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TecPtp54gFDq"
      },
      "source": [
        "#used dataset file to load classes of images  \n",
        "path = '/content/drive/My Drive/Dataset/eeg/'\n",
        "data_dir = path\n",
        "dataset_file = 'eeg_signals_128_sequential_band_all_with_mean_std.pth'\n",
        "\n",
        "#images of dataset with size 224*224\n",
        "photo_path = path + 'photos/images_fullsize.npy'\n",
        "\n",
        "#new images from imageNet with same classes  \n",
        "imgNet = path + 'photos/imageNet_img.npy'\n",
        "imgNet_class = path + 'photos/imageNet_labels.npy' #labels of imageNet\n",
        "\n",
        "#load EEG features and transformer Weights\n",
        "features_path = path + 'features/'\n",
        "\n",
        "# EEG parameters preprocessing\n",
        "l_sh = 200       ## diff\n",
        "r_sh = 50   ## star of time point\n",
        "diff = l_sh"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2uVK_A8YKPc"
      },
      "source": [
        "#loading images from .npy file & resize them\n",
        "def load_photos(path = photo_path):\n",
        "    img_arr = np.load(path)[st_length:en_length]\n",
        "    im_temp = []\n",
        "    if (img_arr.shape[1] != 299 and img_arr.shape[2] != 299):\n",
        "        for i in range(0,en_length-st_length):\n",
        "            im_temp.append(cv2.resize(img_arr[i],(299,299)))\n",
        "            ##299 as the default size of inception v3 \n",
        "        return np.array(im_temp)\n",
        "    else:\n",
        "        return img_arr"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1W3AI-uZ9xC"
      },
      "source": [
        "#extract visual feature for image from inception of imageNetclasses\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "def extract_visual_features(imgs):\n",
        "    #create the inception model\n",
        "    base_model = InceptionV3(include_top = [False], weights = 'imagenet' )\n",
        "\n",
        "    #extract feature from the last layer \n",
        "    new_model=Model(inputs=base_model.input,\n",
        "                    outputs=base_model.get_layer('avg_pool').output)\n",
        "    #predict visual_features for input images\n",
        "    predicts = new_model.predict(imgs)\n",
        "    return predicts"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQXYK9G3xJO1"
      },
      "source": [
        "'''mapping between EEG features extracted from Transformer encoder &\n",
        "visual features extracted from inception model'''\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "EEG_visual_features = np.load(features_path+'visual_features.npy')  \n",
        "#EEG_visual_features it was extracted from incception model \n",
        "\n",
        "def extract_EEG_vector(features):\n",
        "    EEG_features = np.load(features_path+'EEG_features.npy') \n",
        "    #load EEG features extracted from transformer\n",
        "\n",
        "    '''mapping between EEG_transformer and visial features for\n",
        "    the same images trained on the transformer Encoder'''\n",
        "    knr = KNeighborsRegressor(n_neighbors=5)\n",
        "    knr.fit(EEG_visual_features, EEG_features)\n",
        "\n",
        "    '''predict EEG vector using visual features extracted from inception\n",
        "    for images that don't have eeg data'''\n",
        "    return(knr.predict(features))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl10RF6ykCEt"
      },
      "source": [
        "def build_model(vector):\n",
        "    #load weights of last transformer model layer and \n",
        "    #add classifer model with 40 class\n",
        "    init_weights = np.load(features_path+\"trans_weights.npy\",\n",
        "                           allow_pickle=True)\n",
        "    input = tf.keras.layers.Input(shape=(128,))\n",
        "    outputs = layers.Dense(40, activation='sigmoid')(input)\n",
        "    final_model = tf.keras.Model(inputs=input, outputs=outputs)\n",
        "\n",
        "    final_model.compile(optimizer='adam', \n",
        "                        loss='categorical_crossentropy', \n",
        "                        metrics=['accuracy'])\n",
        "    # final_model.summary()\n",
        "\n",
        "    #set weights for the 1st layer outputs\n",
        "    final_model.layers[1].set_weights(init_weights)\n",
        "\n",
        "    #stop traning of the model and make it with fixed size\n",
        "    final_model.layers[-1].trainable = False\n",
        "    return final_model.predict(vector)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOuaGs3Vs-_p"
      },
      "source": [
        "#load dataset using torch \n",
        "def get_labels(label_file = 'None'):\n",
        "    \n",
        "    if (label_file == imgNet_class):\n",
        "        labels = (np.load(imgNet_class)-1)[st_length:en_length]\n",
        "\n",
        "    else:\n",
        "        data1 = torch.load(path + dataset_file)#dictionary of dataset file\n",
        "        dst = data1['dataset']#araay with EEG ,image and label\n",
        "        labels = []\n",
        "        for i in range(1996):\n",
        "             labels.append(dst[i]['label'])\n",
        "        labels = np.array(labels)\n",
        "    return labels \n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWNbO_fn3bO_"
      },
      "source": [
        "def estimate_EEG_vector(st_length = 0,en_length = 1996,\n",
        "                        dataset_test = False):\n",
        "    \n",
        "    if (dataset_test):\n",
        "        imageNet_imgs = load_photos(imgNet)/255\n",
        "        imgNet_visual_features = extract_visual_features(imageNet_imgs)\n",
        "        del(imageNet_imgs)\n",
        "        EEG_vector = extract_EEG_vector(imgNet_visual_features)\n",
        "        del(imgNet_visual_features)\n",
        "        labels = get_labels(imgNet_class)\n",
        "\n",
        "    else:\n",
        "        dataset_imgs = load_photos()/255\n",
        "        dataset_visual_features = extract_visual_features(dataset_imgs)\n",
        "        del(dataset_imgs)\n",
        "        EEG_vector = extract_EEG_vector(dataset_visual_features)\n",
        "        del(dataset_visual_features)\n",
        "        labels = get_labels()\n",
        "    return(EEG_vector,labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iDtldSpfrz4"
      },
      "source": [
        "EEG_vector , labels = estimate_EEG_vector()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm7X3o6FzwZU"
      },
      "source": [
        "st_length = 0\n",
        "en_length = 1996\n",
        "EEG_vector , labels = estimate_EEG_vector(st_length,en_length,True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT8cjYR86taw"
      },
      "source": [
        "#Test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAIrHqs_-YpS"
      },
      "source": [
        "clsfir_preds = build_model(EEG_vector)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iAo0CVq9794",
        "outputId": "32a8a5c8-cc07-42c9-b507-689059416138"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y = np.argmax(clsfir_preds, axis=1)\n",
        "print(accuracy_score(labels, y))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9814629258517034\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
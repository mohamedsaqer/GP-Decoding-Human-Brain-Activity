# -*- coding: utf-8 -*-
"""Copy of l02c01_celsius_to_fahrenheit.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zm-L4VKhbz6vrn3uOSrO1KJWKT8GY3nC

##### Copyright 2018 The TensorFlow Authors.
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow 
from tensorflow import keras
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
from tensorflow.keras import Input , Model
from tensorflow.keras.layers import Conv1D , MaxPooling1D , Flatten , Dense , UpSampling1D , Reshape
import h5py
import numpy as np

from os import listdir
import scipy.io

path = '/content/drive/MyDrive/random.hdf5'
data = h5py.File(path, 'r')

print(data['default'][])

def find_filenames(path_to_dir):
    filenames = listdir(path_to_dir)
    return [filename for filename in filenames]


filenames = find_filenames("/content/drive/MyDrive/data_summary")
print(type(filenames))
label = np.empty(4608,dtype=object)
f=0
for summary in filenames:
    mat = scipy.io.loadmat("/content/drive/MyDrive/data_summary/"+summary)
    temp = mat['experiment_table']
    for i in range(192):
         test = int(temp[i][4])
         if test>96:
            test = (test-97)/3
         elif test<=96:
            test = (test-1)/3
            
         label[f*192+i] = int(test)
    f=f+1
print(label[2000])

dataS = data.get('default')
data=np.empty((4608,128,1230),dtype='d')
data=dataS[:][:][:]

training = data[:3000,:,:] #get first 3000 of file list
testing = data[3000:,:,:] #get last 1608 of file list
training_l = label[:3000] #get first 3000 of file list
testing_l = label[3000:] #get last 1608 of file list
print(training.shape)
print(testing.shape)
print(training_l.shape)
print(testing_l.shape)

del dataS
del data
del filenames
del label

input_sig = Input(shape=(128,1230)) 
x = Conv1D(64,3, activation='relu', padding='valid',data_format='channels_first')(input_sig)
x_ = MaxPooling1D(2,data_format='channels_first')(x)
x1 = Conv1D(32,3, activation='relu', padding='valid',data_format='channels_first')(x_)
x1_ = MaxPooling1D(2,data_format='channels_first')(x1)
x2 = Conv1D(64,3, activation='relu', padding='valid',data_format='channels_first')(x1_)
x2_ = MaxPooling1D(2,data_format='channels_first')(x2)
flat = Flatten()(x2_)
dense = Dense(64,activation = 'relu')(flat)
encoded = Dense(32,activation = 'softmax')(dense)
autoencoder = Model(input_sig, encoded)
autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])

autoencoder.summary()

input_sig = Input(shape=(128,1230))

training = np.asarray(training).astype(np.float32)
training_l = np.asarray(training_l).astype(np.float32)
testing = np.asarray(testing).astype(np.float32)
testing_l = np.asarray(testing_l).astype(np.float32)

autoencoder.fit(training, training_l, epochs=100, verbose=1, validation_data=(testing, testing_l),batch_size=128)

autoencoder.predict(testing[0,0,0])